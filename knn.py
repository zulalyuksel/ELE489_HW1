# -*- coding: utf-8 -*-
"""knn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/169Onf1Use2f6vI_x63mfkTMNsEUVRwKQ
"""

#importing libraries
import numpy as np
from collections import Counter
#Calculate Euclidean distances
def euclidean(x_train, x_test_point):
    distances = np.sqrt(np.sum((x_train - x_test_point) ** 2, axis=1))
    return distances
def NN(distance_point, K):
    nearest_indices = np.argsort(distance_point)[:K]
    return nearest_indices
#Use Counter to count the occurrences of labels in the K nearest neighbors
def voting(nearest_indices, y_train):
    counter_vote = Counter(y_train[nearest_indices])
    y_pred = counter_vote.most_common(1)[0][0] # Return the most common label
    return y_pred
#Calculate Euclidean distances
def euclidean(x_train, x_test_point):
    distances = np.sqrt(np.sum((x_train - x_test_point) ** 2, axis=1))
    return distances
    #Get the indices of the K smallest distances
def NN(distance_point, K):
    nearest_indices = np.argsort(distance_point)[:K]
    return nearest_indices
#Use Counter to count the occurrences of labels in the K nearest neighbors
def voting(nearest_indices, y_train):
    counter_vote = Counter(y_train[nearest_indices])
    y_pred = counter_vote.most_common(1)[0][0] # Return the most common label
    return y_pred
def KNN_euclidean(x_train, y_train, x_test, K):
    y_pred = []
    # Loop over each test sample to make predictions
    for x_test_point in x_test:
        # Step 1: Calculate distances
        distance_point = euclidean(x_train, x_test_point)
        # Step 2: Get the nearest K neighbors
        nearest_indices = NN(distance_point, K)
        # Step 3: Perform majority voting based on nearest neighbors
        y_pred_point = voting(nearest_indices, y_train)
        # Append the prediction to the list
        y_pred.append(y_pred_point)
    return np.array(y_pred)  # Return predictions as a numpy array for easy handling